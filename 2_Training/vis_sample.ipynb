{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd185f7-d9f7-4b0b-8fbd-bdbc336fbc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CPTADDataset2 import CPTADDataset2\n",
    "import xml.etree.ElementTree as ET\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "from transforms import ConvertBCHWtoCBHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f7bb7c-2c05-486e-9c9e-c3777f7462c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('/notebooks/Thesis/1_Preprocessing/annotations_reformatted.xml')\n",
    "videos = tree.getroot()\n",
    "\n",
    "mean = [0.43216, 0.394666, 0.37645]\n",
    "std = [0.22803, 0.22145, 0.216989]\n",
    "\n",
    "ANNO_DIR = '/notebooks/Thesis/annotations/sampleregions/'\n",
    "\n",
    "# https://github.com/pytorch/vision/blob/main/references/video_classification/presets.py\n",
    "video_transform_train = transforms.Compose([\n",
    "                                transforms.ConvertImageDtype(torch.float32),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.Normalize(mean=mean,std=std),\n",
    "                                ConvertBCHWtoCBHW()\n",
    "])\n",
    "                                \n",
    "training_data = CPTADDataset2(ANNO_DIR + \"anno_train.csv\", \n",
    "                             \"../data/Datasets/CPTAD/Videos/\",\n",
    "                             videos,\n",
    "                             nframes=16,\n",
    "                             video_transform=video_transform_train,\n",
    "                             sample_tech='regions')\n",
    "\n",
    "loader = DataLoader(training_data, batch_size=4, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600c40a4-004e-467f-b2bf-6e4c512e1562",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data, label \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/Thesis/2_Training/CPTADDataset2.py:88\u001b[0m, in \u001b[0;36mCPTADDataset2.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame read failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m segment \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_transform:\n\u001b[1;32m     90\u001b[0m        segment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_transform(segment)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got numpy.ndarray"
     ]
    }
   ],
   "source": [
    "data, label = training_data.__getitem__(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bf055-0eb4-4438-b034-32bb78e7b406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
